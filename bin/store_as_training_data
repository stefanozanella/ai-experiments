#!/usr/bin/env ruby
$:.unshift File.join(File.dirname(__FILE__),"..","lib")

require 'bundler/setup'

require 'eventmachine'
require 'em-http'
require 'json'

require 'metric_fetcher'

def compress(data)
  # Cache max value
  max = data.max
  return data.map { |point| 2*point / max - 1 }
end

def split_time_range(from_time, to_time, tick)
  time = to_time
  res = []
  while time >= from_time
    res << time
    time -= tick
  end
  return res
end

def minutes(time)
  (time * 60).round
end

def earliest_sample_end_with(min_time, range_interval)
  return min_time + range_interval
end

def at(time)
  time.strftime("%H:%M_%Y%m%d")
end

EventMachine.run do
  host = 'monitoring.derecom.it'
  metric = 'mercury_derecom_it_collectd.apache-derecom_it.apache_requests.value'
  
  #fetch_from = '08:00_20130111'
  #fetch_to = '09:30_20130111'
  #output_class = :normal
  
  #fetch_from = '10:00_20130111'
  #fetch_to = '10:30_20130111'
  #output_class = :normal
  
  fetch_from = '15:10_20130111'
  fetch_to = '16:20_20130111'
  output_class = :warning

  #fetch_from = '09:20_20130112'
  #fetch_to = '09:40_20130112'
  #output_class = :warning

  #fetch_from = '03:40_20130111'
  #fetch_to = '04:12_20130111'
  #output_class = :warning

  #fetch_from = '19:24_20130111'
  #fetch_to = '19:29_20130111'
  #output_class = :warning

  #fetch_from = '03:34_20130110'
  #fetch_to = '04:10_20130110'
  #output_class = :warning

  #fetch_from = '17:49_20130112'
  #fetch_to = '18:04_20130112'
  #output_class = :warning

  #fetch_from = '23:59_20130111'
  #fetch_to = '00:12_20130112'
  #output_class = :critical

  #fetch_from = '19:29_20130111'
  #fetch_to = '19:32_20130111'
  #output_class = :critical

  #fetch_from = '23:59_20130110'
  #fetch_to = '00:12_20130111'
  #output_class = :critical

  #fetch_from = '19:54_20130111'
  #fetch_to = '20:00_20130111'
  #output_class = :critical

  #fetch_from = '23:59_20130109'
  #fetch_to = '00:22_20130110'
  #output_class = :critical

  #fetch_from = '16:44_20130112'
  #fetch_to = '17:49_20130112'
  #output_class = :critical

  shift = 1
  short_range = 5

  fetch_from_time = Time.parse(fetch_from)
  fetch_to_time = Time.parse(fetch_to)

  puts "Fetching metrics from #{fetch_from_time} to #{fetch_to_time} in #{shift} minutes intervals"
  time_array = split_time_range(fetch_from_time, fetch_to_time, minutes(shift))

  EM::Iterator.new(time_array, 1).map(proc { |sample_end,iter|
    puts "Fetching metrics until #{at(sample_end)} for #{short_range}min"
    
    # If I don't create a new object each iteration, MetricFetcher crashes.
    # If I create a new object here, it crashes if concurrent requests are e.g.
    # 50. Seems to work fine with 20.
    # Suspected issue with MultiRequest and/or Graphite not responding correctly
    apache_requests = MetricFetcher.new host, metric
    apache_requests.fetch :up_to => at(sample_end), :short_interval => "#{short_range}min"
    apache_requests.callback do |sample|
      #puts "Preprocessing metrics"
      normalized_short = compress(sample[:short_term])
      normalized_mid = compress(sample[:mid_term])
      normalized_long = compress(sample[:long_term])
  
      #puts normalized_short.length
      #puts normalized_long.length
  
      #puts "Setting output value"
      output_map = {
        :normal   => [-1,-1,1],
        :warning  => [-1,1,-1],
        :critical => [1,-1,-1] }
    
      iter.return({ :input => [normalized_short, normalized_mid, normalized_long].flatten, :output => output_map[output_class] })
    end
    apache_requests.errback do |error|
      puts error
      iter.return
    end
  }, proc { |samples|
    puts "Got #{samples.length} training samples"

    # Read current training data from file
    training_file = File.join File.dirname(__FILE__), "..", "ext", "training.dat"
    training_set = []

    File.open(training_file, 'r') do |training_data|
      training_data.gets
      while (input_sample = training_data.gets)
        output_sample = training_data.gets
        training_set << { :input => input_sample.split(' ').map { |i| i.to_f }, 
                          :output => output_sample.split(' ').map{ |o| o.to_f } }
      end
    end if File.exists? training_file

    # Add samples to current training data
    training_set = training_set.concat samples

    # TODO (Scramble array)
    #training_set.shuffle!

    # Write training data to file
    File.open(training_file, 'w') do |training_data|
      training_data.puts [training_set.length, training_set[0][:input].length, training_set[0][:output].length].join(' ')
      training_set.each do |training_sample|
        training_data.puts(training_sample[:input].join(' '))
        training_data.puts(training_sample[:output].join(' '))
      end
    end

    EventMachine.stop
  })
end
