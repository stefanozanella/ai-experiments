#!/usr/bin/env ruby
$:.unshift File.join(File.dirname(__FILE__),"..","lib")

require 'bundler/setup'

require 'eventmachine'
require 'em-http'
require 'json'

require 'metric_fetcher'

def compress(data)
  # Cache max value
  max = data.max
  return data.map { |point| 2*point / max - 1 }
end

def split_time_range(from_time, to_time, tick)
  time = to_time
  res = []
  while time >= from_time
    res << time
    time -= tick
  end
  return res
end

def minutes(time)
  (time * 60).round
end

def earliest_sample_end_with(min_time, range_interval)
  return min_time + range_interval
end

def at(time)
  time.strftime("%H:%M_%Y%m%d")
end

EventMachine.run do
  host = 'monitoring.derecom.it'
  metric = 'mercury_derecom_it_collectd.apache-derecom_it.apache_requests.value'
  
  fetch_from = ARGV.shift
  fetch_to = ARGV.shift
  output_class = ARGV.shift.to_sym

  shift = 1
  short_range = 5

  fetch_from_time = Time.parse(fetch_from)
  fetch_to_time = Time.parse(fetch_to)

  puts "Fetching metrics from #{fetch_from_time} to #{fetch_to_time} in #{shift} minutes intervals"
  time_array = split_time_range(fetch_from_time, fetch_to_time, minutes(shift))

  EM::Iterator.new(time_array, 1).map(proc { |sample_end,iter|
    puts "Fetching metrics until #{at(sample_end)} for #{short_range}min"
    
    # If I don't create a new object each iteration, MetricFetcher crashes.
    # If I create a new object here, it crashes if concurrent requests are e.g.
    # 50. Seems to work fine with 20.
    # Suspected issue with MultiRequest and/or Graphite not responding correctly
    apache_requests = MetricFetcher.new host, metric
    apache_requests.fetch :up_to => at(sample_end), :short_interval => "#{short_range}min"
    apache_requests.callback do |sample|
      #puts "Preprocessing metrics"
      normalized_short = compress(sample[:short_term])
      normalized_mid = compress(sample[:mid_term])
      normalized_long = compress(sample[:long_term])
  
      #puts "Setting output value"
      output_map = {
        :normal   => [0,0,1],
        :warning  => [0,1,0],
        :critical => [1,0,0] }
    
      iter.return({ :input => [normalized_short, normalized_mid, normalized_long].flatten, :output => output_map[output_class] })
    end
    apache_requests.errback do |error|
      puts error
      iter.return
    end
  }, proc { |samples|
    puts "Got #{samples.length} training samples"

    # Read current training data from file
    training_file = File.join File.dirname(__FILE__), "..", "ext", "training.dat"
    validation_file = File.join File.dirname(__FILE__), "..", "ext", "validation.dat"
    test_file = File.join File.dirname(__FILE__), "..", "ext", "test.dat"
    training_set = []
    validation_set = []
    test_set = []

    File.open(training_file, 'r') do |training_data|
      training_data.gets
      while (input_sample = training_data.gets)
        output_sample = training_data.gets
        training_set << { :input => input_sample.split(' ').map { |i| i.to_f }, 
                          :output => output_sample.split(' ').map{ |o| o.to_f } }
      end
    end if File.exists? training_file

    File.open(validation_file, 'r') do |training_data|
      training_data.gets
      while (input_sample = training_data.gets)
        output_sample = training_data.gets
        validation_set << { :input => input_sample.split(' ').map { |i| i.to_f }, 
                          :output => output_sample.split(' ').map{ |o| o.to_f } }
      end
    end if File.exists? validation_file

    File.open(test_file, 'r') do |training_data|
      training_data.gets
      while (input_sample = training_data.gets)
        output_sample = training_data.gets
        test_set << { :input => input_sample.split(' ').map { |i| i.to_f }, 
                      :output => output_sample.split(' ').map{ |o| o.to_f } }
      end
    end if File.exists? test_file

    # Scramble array
    samples.shuffle!

    # Add samples to current training data
    training_set = training_set.concat samples[0..(samples.length * 0.70).floor]
    validation_set = validation_set.concat samples[(samples.length * 0.70).ceil..(samples.length * 0.90).floor]
    test_set = test_set.concat samples[(samples.length * 0.90).ceil..-1]

    # Write training, validation and test data to file
    File.open(training_file, 'w') do |training_data|
      training_data.puts [training_set.length, training_set[0][:input].length, training_set[0][:output].length].join(' ')
      training_set.each do |training_sample|
        training_data.puts(training_sample[:input].join(' '))
        training_data.puts(training_sample[:output].join(' '))
      end
    end

    File.open(validation_file, 'w') do |training_data|
      training_data.puts [validation_set.length, validation_set[0][:input].length, validation_set[0][:output].length].join(' ')
      validation_set.each do |training_sample|
        training_data.puts(training_sample[:input].join(' '))
        training_data.puts(training_sample[:output].join(' '))
      end
    end

    File.open(test_file, 'w') do |training_data|
      training_data.puts [test_set.length, test_set[0][:input].length, test_set[0][:output].length].join(' ')
      test_set.each do |training_sample|
        training_data.puts(training_sample[:input].join(' '))
        training_data.puts(training_sample[:output].join(' '))
      end
    end

    EventMachine.stop
  })
end
